{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mountain Car Continuous - PPO"
      ],
      "metadata": {
        "id": "X3EOO7Bsq2Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "_bnO4J2utrEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FOgG30tqlJT"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"MountainCarContinuous-v0\", render_mode=\"rgb_array\", goal_velocity=0.1)  # default goal_velocity=0\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=0.02,batch_size=64)\n",
        "model.learn(total_timesteps=50000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvdrp81IulJr",
        "outputId": "66d03492-b7ff-4604-a0de-4c7ab1aad308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 999      |\n",
            "|    ep_rew_mean     | -52.3    |\n",
            "| time/              |          |\n",
            "|    fps             | 1157     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 999       |\n",
            "|    ep_rew_mean          | -75.5     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 715       |\n",
            "|    iterations           | 2         |\n",
            "|    time_elapsed         | 5         |\n",
            "|    total_timesteps      | 4096      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2494378.5 |\n",
            "|    clip_fraction        | 0.997     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 1.51      |\n",
            "|    explained_variance   | -0.108    |\n",
            "|    learning_rate        | 0.5       |\n",
            "|    loss                 | 6.44      |\n",
            "|    n_updates            | 10        |\n",
            "|    policy_gradient_loss | 0.29      |\n",
            "|    std                  | 0.0491    |\n",
            "|    value_loss           | 34.9      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 999         |\n",
            "|    ep_rew_mean          | -83.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 674         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 201410980.0 |\n",
            "|    clip_fraction        | 0.997       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 2.17        |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.5         |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | 0.168       |\n",
            "|    std                  | 0.0271      |\n",
            "|    value_loss           | 40.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 999         |\n",
            "|    ep_rew_mean          | -87.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 601         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 636675260.0 |\n",
            "|    clip_fraction        | 0.997       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 2.56        |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.5         |\n",
            "|    loss                 | 16          |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | 0.167       |\n",
            "|    std                  | 0.0186      |\n",
            "|    value_loss           | 20.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 999         |\n",
            "|    ep_rew_mean          | -90.1       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 604         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 455541120.0 |\n",
            "|    clip_fraction        | 0.997       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 2.41        |\n",
            "|    explained_variance   | 0.0822      |\n",
            "|    learning_rate        | 0.5         |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | 0.173       |\n",
            "|    std                  | 0.0218      |\n",
            "|    value_loss           | 39.4        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 999        |\n",
            "|    ep_rew_mean          | -91.8      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 611        |\n",
            "|    iterations           | 6          |\n",
            "|    time_elapsed         | 20         |\n",
            "|    total_timesteps      | 12288      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 50019150.0 |\n",
            "|    clip_fraction        | 0.997      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 1.42       |\n",
            "|    explained_variance   | 1.19e-07   |\n",
            "|    learning_rate        | 0.5        |\n",
            "|    loss                 | 2.91       |\n",
            "|    n_updates            | 50         |\n",
            "|    policy_gradient_loss | 0.167      |\n",
            "|    std                  | 0.0603     |\n",
            "|    value_loss           | 20.4       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 999       |\n",
            "|    ep_rew_mean          | -92.9     |\n",
            "| time/                   |           |\n",
            "|    fps                  | 604       |\n",
            "|    iterations           | 7         |\n",
            "|    time_elapsed         | 23        |\n",
            "|    total_timesteps      | 14336     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 3721108.5 |\n",
            "|    clip_fraction        | 0.997     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0.171     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.5       |\n",
            "|    loss                 | 3.11      |\n",
            "|    n_updates            | 60        |\n",
            "|    policy_gradient_loss | 0.169     |\n",
            "|    std                  | 0.212     |\n",
            "|    value_loss           | 3.57      |\n",
            "---------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -93.8         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 599           |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 27            |\n",
            "|    total_timesteps      | 16384         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 70677820000.0 |\n",
            "|    clip_fraction        | 0.997         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 5.03          |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 53.6          |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | 0.168         |\n",
            "|    std                  | 0.00134       |\n",
            "|    value_loss           | 42.7          |\n",
            "-------------------------------------------\n",
            "----------------------------------------------\n",
            "| rollout/                |                  |\n",
            "|    ep_len_mean          | 999              |\n",
            "|    ep_rew_mean          | -94.5            |\n",
            "| time/                   |                  |\n",
            "|    fps                  | 598              |\n",
            "|    iterations           | 9                |\n",
            "|    time_elapsed         | 30               |\n",
            "|    total_timesteps      | 18432            |\n",
            "| train/                  |                  |\n",
            "|    approx_kl            | 41824810000000.0 |\n",
            "|    clip_fraction        | 0.997            |\n",
            "|    clip_range           | 0.2              |\n",
            "|    entropy_loss         | 8.57             |\n",
            "|    explained_variance   | 1.79e-07         |\n",
            "|    learning_rate        | 0.5              |\n",
            "|    loss                 | 12.6             |\n",
            "|    n_updates            | 80               |\n",
            "|    policy_gradient_loss | 0.169            |\n",
            "|    std                  | 4.12e-05         |\n",
            "|    value_loss           | 21.9             |\n",
            "----------------------------------------------\n",
            "-----------------------------------------------\n",
            "| rollout/                |                   |\n",
            "|    ep_len_mean          | 999               |\n",
            "|    ep_rew_mean          | -95               |\n",
            "| time/                   |                   |\n",
            "|    fps                  | 601               |\n",
            "|    iterations           | 10                |\n",
            "|    time_elapsed         | 34                |\n",
            "|    total_timesteps      | 20480             |\n",
            "| train/                  |                   |\n",
            "|    approx_kl            | 115297130000000.0 |\n",
            "|    clip_fraction        | 0.95              |\n",
            "|    clip_range           | 0.2               |\n",
            "|    entropy_loss         | 8.69              |\n",
            "|    explained_variance   | 0                 |\n",
            "|    learning_rate        | 0.5               |\n",
            "|    loss                 | 5.28              |\n",
            "|    n_updates            | 90                |\n",
            "|    policy_gradient_loss | 0.161             |\n",
            "|    std                  | 4.08e-05          |\n",
            "|    value_loss           | 43.4              |\n",
            "-----------------------------------------------\n",
            "-----------------------------------------------\n",
            "| rollout/                |                   |\n",
            "|    ep_len_mean          | 999               |\n",
            "|    ep_rew_mean          | -95.5             |\n",
            "| time/                   |                   |\n",
            "|    fps                  | 592               |\n",
            "|    iterations           | 11                |\n",
            "|    time_elapsed         | 38                |\n",
            "|    total_timesteps      | 22528             |\n",
            "| train/                  |                   |\n",
            "|    approx_kl            | 107224765000000.0 |\n",
            "|    clip_fraction        | 0.994             |\n",
            "|    clip_range           | 0.2               |\n",
            "|    entropy_loss         | 8.7               |\n",
            "|    explained_variance   | -1.19e-07         |\n",
            "|    learning_rate        | 0.5               |\n",
            "|    loss                 | 19.6              |\n",
            "|    n_updates            | 100               |\n",
            "|    policy_gradient_loss | 0.167             |\n",
            "|    std                  | 4.02e-05          |\n",
            "|    value_loss           | 68.9              |\n",
            "-----------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -95.8         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 596           |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 41            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.3900142e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.7           |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.8          |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -2.15e-07     |\n",
            "|    std                  | 4.02e-05      |\n",
            "|    value_loss           | 70.5          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -96.1        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 600          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.126961e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.7          |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.8         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -4.64e-08    |\n",
            "|    std                  | 4.01e-05     |\n",
            "|    value_loss           | 70.5         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -96.4         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 598           |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 47            |\n",
            "|    total_timesteps      | 28672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.6077032e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.7           |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.8          |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -7.75e-08     |\n",
            "|    std                  | 4.01e-05      |\n",
            "|    value_loss           | 70.5          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -96.6         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 590           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 52            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.3671815e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.71          |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.7          |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -1.9e-07      |\n",
            "|    std                  | 4.01e-05      |\n",
            "|    value_loss           | 70.4          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -96.9         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 594           |\n",
            "|    iterations           | 16            |\n",
            "|    time_elapsed         | 55            |\n",
            "|    total_timesteps      | 32768         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.8184226e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.71          |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.7          |\n",
            "|    n_updates            | 150           |\n",
            "|    policy_gradient_loss | 1.04e-07      |\n",
            "|    std                  | 3.99e-05      |\n",
            "|    value_loss           | 70.4          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -97          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 595          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001491122 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.71         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.8         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -1.85e-08    |\n",
            "|    std                  | 3.92e-05     |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -97.2         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 593           |\n",
            "|    iterations           | 18            |\n",
            "|    time_elapsed         | 62            |\n",
            "|    total_timesteps      | 36864         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.0408224e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.73          |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.7          |\n",
            "|    n_updates            | 170           |\n",
            "|    policy_gradient_loss | -1.84e-07     |\n",
            "|    std                  | 3.89e-05      |\n",
            "|    value_loss           | 70.4          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -97.3        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 592          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.584691e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.74         |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.8         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | 7.26e-08     |\n",
            "|    std                  | 3.9e-05      |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -97.5         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 592           |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 69            |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.4106354e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.73          |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.7          |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | 1.26e-07      |\n",
            "|    std                  | 3.93e-05      |\n",
            "|    value_loss           | 70.4          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -97.6        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 593          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007045008 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.74         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -4.43e-07    |\n",
            "|    std                  | 3.78e-05     |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -97.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 588          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.314367e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.76         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | 1.75e-07     |\n",
            "|    std                  | 3.79e-05     |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 999           |\n",
            "|    ep_rew_mean          | -97.8         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 590           |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 79            |\n",
            "|    total_timesteps      | 47104         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.7571957e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | 8.76          |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.5           |\n",
            "|    loss                 | 17.7          |\n",
            "|    n_updates            | 220           |\n",
            "|    policy_gradient_loss | -3.43e-07     |\n",
            "|    std                  | 3.78e-05      |\n",
            "|    value_loss           | 70.4          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -97.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 587          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.891787e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.77         |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | 1.23e-07     |\n",
            "|    std                  | 3.78e-05     |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 999          |\n",
            "|    ep_rew_mean          | -98          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 588          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002715811 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 8.76         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.5          |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 2.57e-07     |\n",
            "|    std                  | 3.88e-05     |\n",
            "|    value_loss           | 70.4         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x79394061bbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testowanie wytrenowanego modelu\n",
        "vec_env = model.get_env()\n",
        "obs = vec_env.reset()\n",
        "num_episodes = 5000\n",
        "\n",
        "\n",
        "episode_rewards = []\n",
        "for episode in range(num_episodes):\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, info = vec_env.step(action)\n",
        "        episode_reward += sum(reward)\n",
        "    episode_rewards.append(episode_reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "V07SxoGHv77h",
        "outputId": "1005c783-8cc7-4720-868d-467c0fd744c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e043d7e4e7a7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \"\"\"\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert to numpy, and reshape to the original action shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc, assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTaken\u001b[0m \u001b[0maction\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \"\"\"\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTorchObs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi_features_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mlatent_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTorchObs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiagGaussianDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;31m# Here mean_actions are the logits before the softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[1;32m    163\u001b[0m         \u001b[0maction_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     raise ValueError(\n\u001b[1;32m     72\u001b[0m                         \u001b[0;34mf\"Expected parameter {param} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def get_moving_avgs(arr, window):\n",
        "        return np.convolve(arr, np.ones(window), 'valid') / window\n",
        "\n",
        "window_size = 1\n",
        "moving_avgs = get_moving_avgs(episode_rewards, window_size)\n",
        "\n",
        "\n",
        "plt.plot(moving_avgs)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('  Reward')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "cAVJ65LMvmeg",
        "outputId": "b33fad7c-78fd-4dd8-ff2b-021aebc7adca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4Jrdvivu8p5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}